{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845f94b5",
   "metadata": {},
   "source": [
    "# LangChain + Gemini/Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bbe8d",
   "metadata": {},
   "source": [
    "## Introducci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3db1c5",
   "metadata": {},
   "source": [
    "### Instalaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5cd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda create -n langchain python=3.12 -y\n",
    "#conda activate langchain\n",
    "#conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y     |    pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
    "#pip3 install langchain langchain-community pypdf openai chromadb tiktoken sentence-transformers transformers ipykernel langchain-google-genai langchain_ollama langchain_experimental duckduckgo-search ddgs wikipedia pinecone langchain-pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df562a06",
   "metadata": {},
   "source": [
    "#### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8ef6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c7ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_lm(text: str):\n",
    "        display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46172c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Modelo Gemini u Ollama\n",
    "# llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite', google_api_key=os.getenv(\"GOOGLE_API_KEY\"), temperature=0.7) \n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:4b\", temperature=0.7)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f13b3f",
   "metadata": {},
   "source": [
    "## 1. Ejemplos base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d6c56",
   "metadata": {},
   "source": [
    "### Conversaci√≥n simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba7a9962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Los principales beneficios de utilizar **LunaChain** (un blockchain desarrollado por la red **Terra**), incluyen:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. **Escalabilidad y rendimiento**\n",
       "- **Alto throughput**: Basado en un mecanismo de consenso **Proof of Stake (PoS)**, permite transacciones r√°pidas y con bajo costo.\n",
       "- **Suficiente capacidad de procesamiento**: Dise√±ado para manejar un alto volumen de transacciones, ideal para aplicaciones de alto tr√°fico (ej: DeFi, NFTs, trading de criptomonedas).\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **Seguridad y confiabilidad**\n",
       "- **Mecanismo de consenso seguro**: La utilizaci√≥n de PoS reduce el riesgo de ataques a escalas (como los ataques de tipo \"51%\").\n",
       "- **Integraci√≥n con Terra**: Como parte del ecosistema **Terra**, la red se basa en la criptomoneda **Luna**, que es una criptomoneda est√°ndar (stablecoin) con valor fijo contra el d√≥lar estadounidense.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **Interoperabilidad**\n",
       "- **Soporte para redes de blockchain**: LunaChain permite transferir activos (como tokens, NFTs, criptomonedas) entre diferentes redes de blockchain, facilitando el intercambio de valor y datos.\n",
       "- **Comunicaci√≥n con otras redes**: La red est√° dise√±ada para interactuar con otras tecnolog√≠as de blockchain (como Ethereum, Binance Smart Chain, etc.).\n",
       "\n",
       "---\n",
       "\n",
       "### 4. **Gesti√≥n de la cadena de bloques**\n",
       "- **Gesti√≥n descentralizada**: La red no tiene un control central, lo que garantiza la libertad de la red y la resistencia a la censura.\n",
       "- **Gesti√≥n de la criptomoneda Luna**: El token Luna es utilizado para validar la red y participar en decisiones del ecosistema.\n",
       "\n",
       "---\n",
       "\n",
       "### 5. **Ecosistema de aplicaciones**\n",
       "- **Aplicaciones DeFi**: LunaChain ofrece soluciones de DeFi (como pr√©stamos, trading, y activos de valor) con caracter√≠sticas de seguridad y rendimiento.\n",
       "- **NFTs y tokenizaci√≥n**: Permite la creaci√≥n de NFTs y tokens de valor, ideales para el mercado de arte, juego y inversi√≥n.\n",
       "- **Aplicaciones de pago**: Soporte para transacciones seguras y r√°pidas, ideal para el comercio digital y la econom√≠a de valor.\n",
       "\n",
       "---\n",
       "\n",
       "### 6. **Gesti√≥n de la comunidad**\n",
       "- **Modelo de gesti√≥n descentralizada**: Los usuarios pueden propuestas y votar en decisiones del ecosistema, garantizando una evoluci√≥n flexible y coherente con las necesidades de la comunidad.\n",
       "- **Comunidad activa**: El ecosistema est√° construido sobre la participaci√≥n de la comunidad, lo que mejora la innovaci√≥n y la resiliencia de la red.\n",
       "\n",
       "---\n",
       "\n",
       "### 7. **Simplicidad y accesibilidad**\n",
       "- **Interfaz amigable**: Ofrece una interfaz f√°cil de usar para usuarios individuales y empresas.\n",
       "- **Accesibilidad para todo tipo de usuarios**: Ideal para personas que desean participar en la econom√≠a digital sin necesidad de conocimientos t√©cnicos avanzados.\n",
       "\n",
       "---\n",
       "\n",
       "### 8. **Sostenibilidad y energ√≠a**\n",
       "- **Energ√≠a eficiente**: El mecanismo de consenso PoS consume menos energ√≠a que los sistemas de consenso basados en CPU o GPU.\n",
       "- **Eco-friendly**: Contribuye a la sostenibilidad de la red al minimizar el consumo de recursos.\n",
       "\n",
       "---\n",
       "\n",
       "### Resumen de beneficios clave:\n",
       "- **Escalabilidad y rendimiento**  \n",
       "- **Seguridad y confiabilidad**  \n",
       "- **Interoperabilidad**  \n",
       "- **Ecosistema diverso**  \n",
       "- **Gesti√≥n descentralizada**  \n",
       "- **Simplicidad y accesibilidad**  \n",
       "- **Sostenibilidad y eficiencia energ√©tica**\n",
       "\n",
       "LunaChain es una plataforma clave en el ecosistema de **Terra**, ofreciendo una combinaci√≥n de innovaci√≥n, seguridad y accesibilidad para el desarrollo de aplicaciones blockchain."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Repuesta simple\n",
    "response = llm.invoke(\"¬øCu√°les son los principales beneficios de usar LangChain?\")\n",
    "print_lm(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95884932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El **LangChain** es un framework de desarrollo de modelos de lenguaje (LLM) que ofrece una serie de beneficios clave para integrar y utilizar modelos de lenguaje en aplicaciones pr√°cticas. A continuaci√≥n, se detallan los principales beneficios detallados:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. **Flexibilidad y adaptabilidad**\n",
       "   - **Integraci√≥n en diversos entornos**: LangChain permite integrar modelos de lenguaje en aplicaciones web, m√≥viles, APIs, sistemas de base de datos y m√°s, sin necesidad de reescribir c√≥digo complejo.\n",
       "   - **Personalizaci√≥n de modelos**: Se puede ajustar los modelos para cumplir con necesidades espec√≠ficas (ej.: fine-tuning para tareas espec√≠ficas como traducci√≥n, generaci√≥n de texto o an√°lisis de sentimiento).\n",
       "   - **Soporte para m√∫ltiples modelos**: Ofrece herramientas para manejar distintos modelos de lenguaje (como GPT-3.5, GPT-4, TAYLOR, etc.) seg√∫n el contexto del proyecto.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **Optimizaci√≥n de rendimiento**\n",
       "   - **Ejecuci√≥n eficiente**: Incluye herramientas para reducir el uso de recursos (ej.: cuantizaci√≥n, prunning o compresi√≥n de modelos) para mejorar la eficiencia en dispositivos con limitaciones de capacidad (ej.: dispositivos m√≥viles o servidores low-cost).\n",
       "   - **Gesti√≥n de versiones**: Permite mantener y actualizar modelos de forma continua, garantizando que se puedan usar versiones optimizadas sin reemplazar completamente el modelo anterior.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **Seguridad y privacidad**\n",
       "   - **Protecci√≥n de datos**: Ofrece mecanismos para cifrar datos sensibles o limitar el acceso a modelos en entornos de producci√≥n.\n",
       "   - **Cumplimiento de regulaciones**: Ayuda a cumplir normativas como GDPR o HIPAA al gestionar el entrenamiento y uso de modelos de lenguaje de forma responsable.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. **Integraci√≥n con herramientas y servicios**\n",
       "   - **SDKs y APIs**: Permite conectar con servicios de cloud (ej.: Azure, AWS, Google Cloud) o plataformas de desarrollo (ej.: GitHub, HuggingFace) para acceder a modelos de lenguaje en tiempo real.\n",
       "   - **Ecosistema de herramientas**: Incluye bibliotecas o m√≥dulos para tareas comunes (ej.: gestionar datos, hacer llamadas a APIs, manejar logs).\n",
       "\n",
       "---\n",
       "\n",
       "### 5. **Dise√±o de pipelines y m√≥dulos**\n",
       "   - **Modularidad**: Permite estructurar aplicaciones en m√≥dulos independientes (ej.: un m√≥dulo para procesamiento de texto, otro para an√°lisis de sentimiento), facilitando la mantenibilidad y escalabilidad.\n",
       "   - **Pipelines de trabajo**: Ofrece herramientas para automatizar procesos como la preprocesaci√≥n de datos, la generaci√≥n de texto, el an√°lisis de contenido, etc.\n",
       "\n",
       "---\n",
       "\n",
       "### 6. **Documentaci√≥n y soporte**\n",
       "   - **Documentaci√≥n detallada**: Incluye gu√≠as y ejemplos para ayudar a usuarios nuevos a entender c√≥mo utilizar el framework.\n",
       "   - **Comunidad activa**: Una comunidad de desarrolladores que comparte soluciones, mejoras y recursos, facilitando el aprendizaje y el crecimiento del uso de LangChain.\n",
       "\n",
       "---\n",
       "\n",
       "### 7. **Escalabilidad y escalabilidad**\n",
       "   - **Scales de modelos**: Permite escalar modelos a diferentes tama√±os (ej.: modelos peque√±os para tareas espec√≠ficas y modelos grandes para tareas de alto rendimiento).\n",
       "   - **Ejecuci√≥n en entornos distribuidos**: Facilita la distribuci√≥n de modelos en m√∫ltiples nodos para procesar grandes vol√∫menes de datos o realizar tareas paralelas.\n",
       "\n",
       "---\n",
       "\n",
       "### 8. **Gesti√≥n de recursos y optimizaci√≥n**\n",
       "   - **Gesti√≥n de recursos de hardware**: Ofrece herramientas para optimizar el uso de CPU, RAM y GPU, minimizando el consumo de recursos y mejorando el rendimiento.\n",
       "   - **Ejecuci√≥n en entornos de inferencia**: Permite ejecutar modelos de lenguaje en entornos de inferencia (ej.: servidores, dispositivos m√≥viles) con optimizaciones espec√≠ficas.\n",
       "\n",
       "---\n",
       "\n",
       "### 9. **Compatibilidad con frameworks de desarrollo**\n",
       "   - **Integraci√≥n con herramientas de desarrollo**: Ayuda a integrar modelos de lenguaje con frameworks de desarrollo como TensorFlow, PyTorch, o cuadros de desarrollo de aplicaciones (ej.: React, Flutter) para una mayor flexibilidad en la construcci√≥n de aplicaciones.\n",
       "\n",
       "---\n",
       "\n",
       "### 10. **Ejemplo pr√°ctico de beneficio**\n",
       "   - **Tarea espec√≠fica**: Un equipo de desarrollo puede usar LangChain para crear una aplicaci√≥n de asistencia en l√≠nea que genere contenido para blogs o redes sociales. Al usar LangChain, pueden personalizar el modelo para generar contenido en varios idiomas, optimizar la velocidad de respuesta y garantizar la privacidad de los datos de los usuarios.\n",
       "\n",
       "---\n",
       "\n",
       "### Conclusi√≥n\n",
       "LangChain se destaca por su **flexibilidad, eficiencia, seguridad y integraci√≥n** con herramientas de desarrollo, permitiendo a los usuarios crear aplicaciones de lenguaje de forma escalable y personalizable. Su enfoque en la **optimizaci√≥n de recursos** y el **dise√±o modular** lo convierte en un puente efectivo entre la tecnolog√≠a de modelos de lenguaje y las necesidades de las aplicaciones reales."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Respuesta en \"stream\"\n",
    "from IPython.display import display, Markdown\n",
    "from IPython.display import update_display\n",
    "\n",
    "def stream_llm(prompt: str):\n",
    "    full_response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in llm.stream(prompt):\n",
    "        full_response += chunk.content\n",
    "        update_display(Markdown(full_response), display_id=display_handle.display_id)\n",
    "stream_llm(\"¬øCu√°les son los principales beneficios de usar LangChain, detalladamente?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f398b0f",
   "metadata": {},
   "source": [
    "### Uso de las plantillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09c19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Redes Neuronales Convolucionales (CNNs): Una Visi√≥n Detallada**\n",
       "\n",
       "Las **redes neuronales convolucionales** (CNNs) son una de las tecnolog√≠as m√°s poderosas en la inteligencia artificial, especialmente en el √°mbito de la **visi√≥n por computadora**. Dise√±adas para manejar datos en forma de im√°genes o registros de video, CNNs capturan patrones locales y hierarquizan la informaci√≥n, lo que las hace ideales para tareas como clasificaci√≥n de im√°genes, detecci√≥n de objetos, segmentaci√≥n de im√°genes, y m√°s.\n",
       "\n",
       "---\n",
       "\n",
       "### **¬øQu√© son las CNNs?**\n",
       "Las CNNs son una variante de redes neuronales profundas que emplean **operaciones de convoluci√≥n** para procesar datos en 2D (como im√°genes). A diferencia de redes neuronales tradicionales, las CNNs est√°n optimizadas para capturar **patrones locales** y **hierarqu√≠as espaciales**, lo que les permite reconocer estructuras complejas en im√°genes sin necesidad de mapear todo el espacio (como en redes neuronales convolucionales de alto nivel).\n",
       "\n",
       "---\n",
       "\n",
       "### **Estructura de una CNN**\n",
       "\n",
       "Una CNN t√≠pica consta de **tres tipos de capas principales**:\n",
       "\n",
       "1. **Capas de Convoluci√≥n (Convolutional Layers)**  \n",
       "   - Aplican **filtros (kernel)** a la entrada para extraer caracter√≠sticas locales (como bordes, texturas, formas).\n",
       "   - Cada filtro es un matriz de n√∫meros que se mueve por la imagen (con *stride* y *padding* para ajustar el tama√±o).\n",
       "   - Ejemplo: Un filtro de 3x3 puede detectar bordes o detalles en una imagen.\n",
       "\n",
       "2. **Capas de Pooling (Pooling Layers)**  \n",
       "   - Reducen el tama√±o de la imagen para reducir el n√∫mero de par√°metros y el ruido, pero preservan la informaci√≥n esencial.\n",
       "   - La **funci√≥n de m√°ximo (Max Pooling)** es com√∫n, ya que mantiene el m√°ximo valor de una regi√≥n, lo que ayuda a la red a enfocarse en los detalles m√°s importantes.\n",
       "   - Ejemplo: Un *stride* de 2 y un *padding* de 1 permiten reducir el tama√±o de la imagen.\n",
       "\n",
       "3. **Capas de Conexi√≥n Final (Fully Connected Layers)**  \n",
       "   - Convierten los datos de la capa de salida (que son valores de probabilidad o nodos) en una clasificaci√≥n final.\n",
       "   - Estas capas son similares a las de redes neuronales convolucionales tradicionales, pero est√°n ubicadas al final de la red.\n",
       "\n",
       "---\n",
       "\n",
       "### **Funcionamiento de las CNNs**\n",
       "\n",
       "1. **Procesamiento de Entrada**  \n",
       "   - La entrada es una imagen (o registro de video) de tama√±o alto (ej. 224x224 pixeles para im√°genes de 3 canales).\n",
       "   - Las capas de convoluci√≥n aplican filtros para extraer caracter√≠sticas (ej. bordes, texturas).\n",
       "\n",
       "2. **Hierarqu√≠a de Informaci√≥n**  \n",
       "   - Las capas de convoluci√≥n crean **campos de caracter√≠sticas** (feature maps) que representan diferentes niveles de abstracci√≥n.\n",
       "   - Por ejemplo:\n",
       "     - **Capa 1**: Detecta bordes, texturas.\n",
       "     - **Capa 2**: Detecta formas complejas (ej. c√≠rculos, cuadrados).\n",
       "     - **Capa 3**: Detecta objetos grandes (ej. personas, veh√≠culos).\n",
       "\n",
       "3. **Reducci√≥n Espacial**  \n",
       "   - Las capas de pooling reducen el tama√±o de la imagen, lo que permite que la red se enfoque en las caracter√≠sticas m√°s relevantes.\n",
       "\n",
       "4. **Activaci√≥n y Optimizaci√≥n**  \n",
       "   - Se usan funciones como **ReLU** (Rectified Linear Unit) para activar solo los valores positivos, evitando la saturaci√≥n.\n",
       "   - El **backpropagation** y algoritmos como **Adam** se emplean para ajustar los par√°metros de los filtros mediante el **error de p√©rdida**.\n",
       "\n",
       "---\n",
       "\n",
       "### **Ventajas de las CNNs**\n",
       "\n",
       "- **Capacidad de capturar patrones locales**: Detectan bordes, texturas, y formas en im√°genes.\n",
       "- **Robustez a cambios en la entrada**: Son invariantes a rotaciones, escalas y truncados.\n",
       "- **Reducci√≥n de par√°metros**: Usan **pesos compartidos** (los mismos filtros en diferentes capas), lo que reduce el n√∫mero de par√°metros.\n",
       "- **Eficiencia computacional**: Las capas de pooling y convoluci√≥n permiten procesar im√°genes de manera eficiente.\n",
       "\n",
       "---\n",
       "\n",
       "### **Aplicaciones Comunes**\n",
       "\n",
       "1. **Clasificaci√≥n de Im√°genes**  \n",
       "   - Ejemplo: Detectar si una imagen contiene un rostro (en redes como **AlexNet** o **ResNet**).\n",
       "2. **Detecci√≥n de Objetos**  \n",
       "   - Ejemplo: Identificar veh√≠culos, personas en im√°genes de video.\n",
       "3. **Segmentaci√≥n de Im√°genes**  \n",
       "   - Ejemplo: Dividir una imagen en regiones (como en el caso de la **U-Net**).\n",
       "4. **Reconocimiento de Rostros**  \n",
       "   - Ejemplo: Algoritmos como **FaceNet**.\n",
       "\n",
       "---\n",
       "\n",
       "### **Ejemplos de Arquitecturas Notables**\n",
       "\n",
       "- **AlexNet** (2012): Primera red CNN con √©xito en imagen de 2012.\n",
       "- **VGGNet** (2014): Arquitectura modular con 16 capas convolucionales.\n",
       "- **ResNet** (2015): Resuelve el problema del **vanishing gradient** mediante capas de **residual**.\n",
       "- **EfficientNet** (2021): Combina eficiencia y precisi√≥n con una arquitectura h√≠brida.\n",
       "\n",
       "---\n",
       "\n",
       "### **Desaf√≠os y Consideraciones**\n",
       "\n",
       "- **Ejemplo de desaf√≠o**: Las CNNs pueden ser computacionalmente intensas, especialmente con im√°genes grandes.\n",
       "- **Saturaci√≥n de la red**: Si los filtros se ajustan incorrectamente, la red puede no aprender bien.\n",
       "- **Carga de memoria**: Las capas de pooling y convoluci√≥n requieren un manejo adecuado de la memoria.\n",
       "\n",
       "---\n",
       "\n",
       "### **Conclusi√≥n**\n",
       "\n",
       "Las CNNs son fundamentales en la inteligencia artificial moderna, especialmente en tareas de **visi√≥n por computadora**. Su capacidad para capturar patrones locales y hierarquizar la informaci√≥n las hace √∫nicas. A trav√©s de capas de convoluci√≥n, pooling y conexi√≥n final, las CNNs pueden clasificar, detectar y segmentar im√°genes de manera eficiente y precisa. Con avances en arquitecturas como **ResNet** y **EfficientNet**, las CNNs contin√∫an evolucionando para abordar problemas complejos en im√°genes y registros de video."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Respuesta simple\n",
    "template = \"\"\"Act√∫a como un experto en {tema}. Proporciona una explicaci√≥n detallada sobre: {concepto}\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"tema\", \"concepto\"],template=template)\n",
    "chain = prompt  | llm\n",
    "response = chain.invoke({\"tema\": \"inteligencia artificial\", \"concepto\": \"redes neuronales convolucionales\"})\n",
    "print_lm(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a937f41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Redes Neuronales Convolucionales (CNN)** son una arquitectura de aprendizaje autom√°tico inspirada en la estructura del sistema visual humano. Se utilizan ampliamente en tareas de procesamiento de im√°genes y datos espaciales, como reconocimiento de objetos, detecci√≥n de caracter√≠sticas y segmentaci√≥n de im√°genes. Su dise√±o se basa en la idea de capturar patrones locales y reducir la dimensionalidad del espacio de caracter√≠sticas, lo que la hace eficiente para datos con estructura espacial.\n",
       "\n",
       "---\n",
       "\n",
       "### **Componentes Principales de una CNN**\n",
       "1. **Capa Convolutiva (Convolutional Layer):**  \n",
       "   - **Funci√≥n:** Aplica **filtros (kernels)** peque√±os (por ejemplo, 3x3 o 5x5) a la entrada para detectar patrones locales (como bordes, texturas, formas).  \n",
       "   - **Proceso:**  \n",
       "     - La entrada (como una imagen) se convierte en una **matriz de caracter√≠sticas** (feature map) al aplicar m√∫ltiples filtros.  \n",
       "     - Cada filtro genera una **salida** (feature map) que representa la presencia de patrones espec√≠ficos en la imagen.  \n",
       "     - **Ejemplo:** Un filtro de 3x3 puede detectar bordes en una imagen.\n",
       "\n",
       "2. **Capa de Pooling (Pooling Layer):**  \n",
       "   - **Funci√≥n:** Reduce la dimensionalidad de la entrada y **robusta la red** contra desplazamientos espaciales.  \n",
       "   - **Tipo m√°s com√∫n:** **Max Pooling** (m√°s eficiente que el average pooling).  \n",
       "   - **Proceso:**  \n",
       "     - Se selecciona el valor m√°ximo de una regi√≥n de la entrada (por ejemplo, 2x2) y se mantiene.  \n",
       "     - **Ejemplo:** Si un √°rea de la imagen tiene valores 10, 20, 15, 25, el pooling selecciona 25 como valor de salida.\n",
       "\n",
       "3. **Capa de Conexi√≥n Fuera de L√≠nea (Fully Connected Layer):**  \n",
       "   - **Funci√≥n:** Conecta todas las neuronas de la capa anterior a las neuronas de la capa posterior, permitiendo la aprendizaje de patrones complejos.  \n",
       "   - **Proceso:**  \n",
       "     - La salida de la capa de pooling se flatten (convertir en un vector) y se pasa a una capa densa (dense layer).  \n",
       "     - La capa densa genera una **salida final** (por ejemplo, en un problema de clasificaci√≥n, una probabilidad de cada clase).\n",
       "\n",
       "---\n",
       "\n",
       "### **Estructura de la CNN**\n",
       "- **Entrada:** Datos espaciales (im√°genes, videos, sonidos, etc.).  \n",
       "- **Capas Convolucionales:**  \n",
       "  - 1 o m√°s capas convolucionales para capturar patrones locales.  \n",
       "  - Capa de pooling para reducir la dimensionalidad y aumentar la robustez.  \n",
       "- **Capa de Conexi√≥n Fuera de L√≠nea (FC):**  \n",
       "  - Conecta todas las neuronas de la capa anterior a las de la salida.  \n",
       "- **Salida:** Valor final (por ejemplo, una probabilidad en una clasificaci√≥n).\n",
       "\n",
       "---\n",
       "\n",
       "### **Ejemplo Pr√°ctico: Reconocimiento de Objetos**\n",
       "1. **Entrada:** Imagen de un auto (ejemplo: 32x32x3).  \n",
       "2. **Capa Convolutiva 1:**  \n",
       "   - Aplica 16 filtros de 3x3 a la imagen, generando 16 feature maps.  \n",
       "   - Cada feature map representa una caracter√≠stica (ej: bordes, texturas).  \n",
       "3. **Capa de Pooling:**  \n",
       "   - Aplica max pooling de 2x2 a cada feature map, reduciendo la dimensi√≥n a 16x16x1.  \n",
       "4. **Capa Convolutiva 2:**  \n",
       "   - Aplica 32 filtros de 3x3 a la entrada reducida, generando 32 feature maps.  \n",
       "   - Cada feature map representa una caracter√≠stica m√°s compleja (ej: forma del auto).  \n",
       "5. **Capa de Pooling:**  \n",
       "   - Reduciendo a 16x16x32.  \n",
       "6. **Capa de Conexi√≥n Fuera de L√≠nea:**  \n",
       "   - Flatten a vector de 16*16*32 = 8192 neuronas.  \n",
       "   - Conectadas a 10 neuronas (para clasificar 10 clases en CIFAR-10).  \n",
       "7. **Salida:** Probabilidad de cada clase (ej: 0.9 para \"auto\" y 0.1 para \"coche de paseo\").\n",
       "\n",
       "---\n",
       "\n",
       "### **Ventajas de las CNN**\n",
       "- **Captura patrones espaciales:** Detecta patrones locales (bordes, texturas) y hierarch√≠as (forma ‚Üí estructura ‚Üí objeto).  \n",
       "- **Eficiente para datos con estructura espacial:** Reducen la cantidad de datos a procesar (ej: no se procesan todas las im√°genes en paralelo).  \n",
       "- **Robustez a desplazamientos:** La capa de pooling mantiene la informaci√≥n clave incluso si el objeto se desplaza en la imagen.  \n",
       "- **Aplicaciones:**  \n",
       "  - Reconocimiento de objetos (deteci√≥n de caras, mascotas).  \n",
       "  - Segmentaci√≥n de im√°genes (seg√∫n regi√≥n de inter√©s).  \n",
       "  - An√°lisis de sonidos (ej: detecci√≥n de sonidos en audio).  \n",
       "\n",
       "---\n",
       "\n",
       "### **Par√°metros Clave**\n",
       "- **Tama√±o del filtro (kernel):** Influye en la resoluci√≥n de la salida.  \n",
       "- **Stride:** Dicte la distancia entre los p√≠xeles que se procesan.  \n",
       "- **Padding:** A√±ade espacios vac√≠os alrededor de la entrada para evitar corte de la imagen.  \n",
       "- **N√∫mero de capas:** M√°s capas permiten capturar patrones m√°s complejos, pero aumentan el n√∫mero de par√°metros y el riesgo de sobreajuste.\n",
       "\n",
       "---\n",
       "\n",
       "### **Ejemplo de Implementaci√≥n (Python con TensorFlow/Keras)**\n",
       "```python\n",
       "model = Sequential()\n",
       "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(32,32,3)))\n",
       "model.add(MaxPooling2D((2,2)))\n",
       "model.add(Conv2D(32, (3,3), activation='relu'))\n",
       "model.add(MaxPooling2D((2,2)))\n",
       "model.add(Flatten())\n",
       "model.add(Dense(10, activation='softmax'))\n",
       "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### **Conclusi√≥n**\n",
       "Las redes neuronales convolucionales son una herramienta poderosa para procesar datos con estructura espacial, gracias a su capacidad de capturar patrones locales y hierarch√≠as. Su dise√±o inspirado en la visi√≥n humana y su eficiencia en im√°genes y sonidos las convierten en la arquitectura est√°ndar en tareas de reconocimiento de objetos, detecci√≥n y segmentaci√≥n. La combinaci√≥n de capas convolucionales, pooling y densas permite una comprensi√≥n profunda de los datos, con aplicaciones en campos como la rob√≥tica, la medicina y la inteligencia artificial."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Respuesta en \"stream\"\n",
    "def stream_llm(stream):\n",
    "    full_response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        full_response += chunk.content\n",
    "        update_display(Markdown(full_response), display_id=display_handle.display_id)\n",
    "\n",
    "template = \"\"\"Act√∫a como un experto en {tema}. Proporciona una explicaci√≥n detallada sobre: {concepto}\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"tema\", \"concepto\"],template=template)\n",
    "chain = prompt  | llm\n",
    "stream_llm(chain.stream({\"tema\": \"inteligencia artificial\", \"concepto\": \"redes neuronales convolucionales\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f0e01",
   "metadata": {},
   "source": [
    "### Uso de memoria para chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da69c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_classic.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4b6ff",
   "metadata": {},
   "source": [
    "#### M√âTODO ANTIGUO QUE SE DEPRECAR√Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76a70208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de la memoria\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38046192",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"La siguiente es una conversaci√≥n amigable entre un humano y un asistente AI.\n",
    "Historial de la conversaci√≥n:\n",
    "{chat_history}\n",
    "Humano: {input}\n",
    "Asistente:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "630654a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7fc9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora la cadena y uso\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d46f6e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mLa siguiente es una conversaci√≥n amigable entre un humano y un asistente AI.\n",
      "Historial de la conversaci√≥n:\n",
      "[]\n",
      "Humano: Qu√© pa√≠s ha ganado m√°s copas del mundo de f√∫tbol?\n",
      "Asistente:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "El pa√≠s que ha ganado m√°s Copas del Mundo de f√∫tbol es Brasil, con 5 t√≠tulos. Los a√±os en los que Brasil gan√≥ la Copa del Mundo fueron: 1958, 1962, 1970, 1994 y 2002."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mLa siguiente es una conversaci√≥n amigable entre un humano y un asistente AI.\n",
      "Historial de la conversaci√≥n:\n",
      "[HumanMessage(content='Qu√© pa√≠s ha ganado m√°s copas del mundo de f√∫tbol?', additional_kwargs={}, response_metadata={}), AIMessage(content='El pa√≠s que ha ganado m√°s Copas del Mundo de f√∫tbol es Brasil, con 5 t√≠tulos. Los a√±os en los que Brasil gan√≥ la Copa del Mundo fueron: 1958, 1962, 1970, 1994 y 2002.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "Humano: Dime jugadores hist√≥ricos de esa selecci√≥n\n",
      "Asistente:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Algunos jugadores hist√≥ricos destacados de la selecci√≥n brasile√±a son:\n",
       "\n",
       "1. **Pel√©** (1958-1970): Considerado uno de los mejores jugadores de todos los tiempos, gan√≥ tres Copas del Mundo con Brasil y es el m√°s emblem√°tico de la historia del f√∫tbol.\n",
       "2. **Garrincha** (1958-1962): Reconocido por su habilidad en el juego de pies y su creatividad, fue clave en las primeras victorias de Brasil en la Copa del Mundo.\n",
       "3. **Ronaldinho** (1990-2002): Famoso por su habilidad t√©cnica y su influencia en el f√∫tbol mundial, gan√≥ la Copa del Mundo en 2002 con Brasil.\n",
       "4. **Ronaldo Naz√°rio** (1990-2006): Jugador de gran prestigio, destac√≥ en las d√©cadas de 1990 y 2000, incluyendo su participaci√≥n en la Copa del Mundo de 2002.\n",
       "5. **Rom√°rio** (1980-2000): Jugador de alto nivel que contribuy√≥ a la selecci√≥n brasile√±a en las d√©cadas de 1980 y 1990, destacando en la Copa del Mundo de 1994.\n",
       "\n",
       "Estos jugadores son algunos de los m√°s emblem√°ticos y destacados en la historia de la selecci√≥n brasile√±a."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mLa siguiente es una conversaci√≥n amigable entre un humano y un asistente AI.\n",
      "Historial de la conversaci√≥n:\n",
      "[HumanMessage(content='Qu√© pa√≠s ha ganado m√°s copas del mundo de f√∫tbol?', additional_kwargs={}, response_metadata={}), AIMessage(content='El pa√≠s que ha ganado m√°s Copas del Mundo de f√∫tbol es Brasil, con 5 t√≠tulos. Los a√±os en los que Brasil gan√≥ la Copa del Mundo fueron: 1958, 1962, 1970, 1994 y 2002.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='Dime jugadores hist√≥ricos de esa selecci√≥n', additional_kwargs={}, response_metadata={}), AIMessage(content='Algunos jugadores hist√≥ricos destacados de la selecci√≥n brasile√±a son:\\n\\n1. **Pel√©** (1958-1970): Considerado uno de los mejores jugadores de todos los tiempos, gan√≥ tres Copas del Mundo con Brasil y es el m√°s emblem√°tico de la historia del f√∫tbol.\\n2. **Garrincha** (1958-1962): Reconocido por su habilidad en el juego de pies y su creatividad, fue clave en las primeras victorias de Brasil en la Copa del Mundo.\\n3. **Ronaldinho** (1990-2002): Famoso por su habilidad t√©cnica y su influencia en el f√∫tbol mundial, gan√≥ la Copa del Mundo en 2002 con Brasil.\\n4. **Ronaldo Naz√°rio** (1990-2006): Jugador de gran prestigio, destac√≥ en las d√©cadas de 1990 y 2000, incluyendo su participaci√≥n en la Copa del Mundo de 2002.\\n5. **Rom√°rio** (1980-2000): Jugador de alto nivel que contribuy√≥ a la selecci√≥n brasile√±a en las d√©cadas de 1980 y 1990, destacando en la Copa del Mundo de 1994.\\n\\nEstos jugadores son algunos de los m√°s emblem√°ticos y destacados en la historia de la selecci√≥n brasile√±a.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "Humano: De qu√© color es su camiseta? \n",
      "Asistente:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "La camiseta de la selecci√≥n brasile√±a es verde y amarillo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print('\\n')\n",
    "    print('-'*70)\n",
    "    message = input('INGRESE SU TEXTO:')\n",
    "    print_lm(conversation.predict(input=message))\n",
    "    print('-'*70)\n",
    "    print('\\n')\n",
    "    if input('Ingresar otro texto? (s/n):').lower() == 'n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929dfe4",
   "metadata": {},
   "source": [
    "#### M√âTODO NUEVO SUGERIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "033ed8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6f6e0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"La siguiente es una conversaci√≥n amigable entre un humano y un asistente AI.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f945a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8cb1423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "conversation = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167afd9e",
   "metadata": {},
   "source": [
    "EL M√âTODO ACTUAL DE STRDAOUTCALLbackHandler no muestro todo como LLMChain verbose = True, tocar√≠a usar LangSmith y es con cuenta y API KEY (muy tedioso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8add50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableWithMessageHistory chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new insert_history chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel<chat_history> chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new load_history chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new check_sync_or_async chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "¬°Hola! üòä La selecci√≥n que ha ganado m√°s Mundiales de F√∫tbol en la historia es **Brasil**, con **5 t√≠tulos** (1950, 1958, 1962, 1970 y 2002). \n",
       "\n",
       "¬°Espero que te haya ayudado! üòÑ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableWithMessageHistory chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new insert_history chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel<chat_history> chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new load_history chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new check_sync_or_async chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "¬°Hola! üòä Aqu√≠ tienes algunos jugadores hist√≥ricos de la selecci√≥n brasile√±a que han ganado **Mundiales de F√∫tbol** (en los que Brasil ha sido campe√≥n):\n",
       "\n",
       "1. **Pel√©** (1958, 1962, 1970) ‚Äì El icono del f√∫tbol mundial, jugador clave en tres ediciones campe√≥n.\n",
       "2. **Garrincha** (1958, 1962) ‚Äì El \"m√°gico\" conocido por su estilo √∫nico y habilidad para el campo.\n",
       "3. **Jairzinho** (1970) ‚Äì Delantero destacado en el Mundial de 1970.\n",
       "4. **Ronaldinho** (2002) ‚Äì Mediocampista talentoso que ayud√≥ a Brasil a ganar el Mundial de 2002.\n",
       "5. **Ronaldo Naz√°rio** (2002) ‚Äì Delantero de gran impacto en el Mundial de 2002.\n",
       "\n",
       "¬°Espero que te guste esta selecci√≥n! üòÑ ¬øNecesitas m√°s detalles sobre alguno de ellos?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableWithMessageHistory chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new insert_history chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableParallel<chat_history> chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new load_history chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new check_sync_or_async chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RunnableSequence chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ChatPromptTemplate chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "¬°Hola! üòä Los colores tradicionales de la indumentaria de la selecci√≥n brasile√±a son **verde y amarelo**. \n",
       "\n",
       "- **Camiseta de casa**: Generalmente en **verde** con detalles amarillos (como bordes, mangas o banderas).  \n",
       "- **Camiseta de visitas**: A menudo en **amarillo** con detalles verdes (como estrellas, l√≠neas o logotipos).  \n",
       "\n",
       "Este combinaci√≥n de colores (verde y amarelo) es uno de los s√≠mbolos m√°s reconocidos en el f√∫tbol mundial, y se usa desde el inicio de la selecci√≥n brasile√±a en los torneos internacionales. \n",
       "\n",
       "¬øTe gustar√≠a saber m√°s sobre alg√∫n detalle espec√≠fico? üòÑ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.callbacks import StdOutCallbackHandler #Para ver el procesamiento \"interno\"\n",
    "handler = StdOutCallbackHandler() # <---- Se crea un handler!!!\n",
    "\n",
    "\n",
    "while True:\n",
    "    print('-' * 70)\n",
    "\n",
    "    message = input('INGRESE SU TEXTO: ')\n",
    "\n",
    "    response = conversation.invoke(\n",
    "        {\"input\": message},\n",
    "        config={\"configurable\": {\"session_id\": \"default\"},\n",
    "                 \"callbacks\": [handler],  # <--- AQu√≠ se a√±ad el handler\n",
    "                }\n",
    "    )\n",
    "\n",
    "    print_lm(response.content)\n",
    "\n",
    "    print('-' * 70)\n",
    "    if input('¬øIngresar otro texto? (s/n): ').lower() == 'n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec567ac6",
   "metadata": {},
   "source": [
    "### An√°lisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e7f6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f195f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_lm(text: str):\n",
    "        display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a3799ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Modelo Gemini u Ollama\n",
    "# llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite', google_api_key=os.getenv(\"GOOGLE_API_KEY\"), temperature=0.7) \n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:4b\", temperature=0.7)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e9bdb7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "# Se crea la plantilla para an√°lisis de sentimiento\n",
    "sentiment_template = \"\"\"Analiza el sentimiento del siguiente texto y clasif√≠calo como negativo, positivo o neutral Proporciona tambi√©n una explicaci√≥n corta de tu an√°lisis\n",
    "Testo : {texto}\n",
    "\n",
    "Formato de respuesta:\n",
    "Sentimiento: [clasificaci√≥n]\n",
    "Explicaci√≥n: [tu an√°lisis]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "47ab6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = PromptTemplate(input_variables=[\"texto\"], template=sentiment_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e758a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creaci√≥n de la cadena\n",
    "sentiment_chain = sentiment_prompt | llm # <--- SIEMPRE primero va el prompt y luego el llm para esto\n",
    "#Texto a analizar\n",
    "text_example = \"El nuevo restaurante super√≥ todas mis expectativas, La comida estaba deliciosa y el servicio fue excelente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42609be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimiento: positivo  \n",
      "Explicaci√≥n: El texto utiliza t√©rminos expresamente positivos como \"deliciosa\" (comida), \"excelente\" (servicio) y \"super√≥ todas mis expectativas\", lo que indica una satisfacci√≥n total y exceso de expectativas en el contexto del restaurante. No hay elementos negativos ni neutros en la frase.\n"
     ]
    }
   ],
   "source": [
    "result = sentiment_chain.invoke({\"texto\": text_example})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f4447",
   "metadata": {},
   "source": [
    "## 2. Integraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fb7e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
